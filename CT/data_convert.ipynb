{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:00<00:00, 502.97it/s]\n",
      "100%|██████████| 333/333 [00:00<00:00, 375.45it/s]\n",
      "100%|██████████| 156/156 [00:00<00:00, 478.01it/s]\n",
      "  0%|          | 3/1082 [00:03<23:55,  1.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images, file[i])\n\u001b[1;32m     13\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(masks, file[i])\n\u001b[0;32m---> 14\u001b[0m \u001b[43mnii_rgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_slices_as_rgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MED-YOLO/m_yolo/nii_rgb.py:13\u001b[0m, in \u001b[0;36msave_slices_as_rgb\u001b[0;34m(image_path, mask_path, output_dir, name, angle)\u001b[0m\n\u001b[1;32m     10\u001b[0m mask_nii \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(mask_path)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get the image and mask data as numpy arrays\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[43mimg_nii\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m mask_nii\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure the image and mask have the same shape\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/site-packages/nibabel/dataobj_images.py:374\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataobj, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/site-packages/nibabel/arrayproxy.py:454\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/site-packages/nibabel/arrayproxy.py:421\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    419\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/site-packages/nibabel/arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    388\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    401\u001b[0m         fileobj,\n\u001b[1;32m    402\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[1;32m    408\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/site-packages/nibabel/volumeutils.py:467\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    466\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[0;32m--> 467\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/med_yolo/lib/python3.11/gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m    505\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 507\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import m_yolo\n",
    "from m_yolo import nii_rgb\n",
    "\n",
    "\n",
    "file = os.listdir('dataset_nii/train/images')\n",
    "images = 'dataset_nii/train/images'\n",
    "masks = 'dataset_nii/train/labels'\n",
    "output_dir = 'dataset/train'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(file))):\n",
    "    image_path = os.path.join(images, file[i])\n",
    "    mask_path = os.path.join(masks, file[i])\n",
    "    nii_rgb.save_slices_as_rgb(image_path, mask_path, output_dir, name=file[i], angle=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: , 44792\n",
      "labels: , 44792\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: , 278190\n",
      "labels: , 278190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278190/278190 [12:39<00:00, 366.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# read the files from image and label directory and make sure that their size is the same\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "files = os.listdir('dataset/train/images')\n",
    "print('images: ,', len(files))\n",
    "files = os.listdir('dataset/train/masks')\n",
    "print('labels: ,', len(files))\n",
    "\n",
    "unique_values = []\n",
    "for i in tqdm.tqdm(range(len(files))):\n",
    "    image_name = 'dataset/train/images/' + files[i]\n",
    "    mask_name = 'dataset/train/masks/' + files[i]\n",
    "    mask = plt.imread(mask_name)\n",
    "    uniq = np.unique(mask)\n",
    "    unique_values.append(len(uniq))\n",
    "    img = plt.imread(image_name)\n",
    "\n",
    "\n",
    "    if plt.imread(image_name)[:,:,0].shape  == plt.imread(mask_name).shape:\n",
    "        continue    \n",
    "    else:\n",
    "        print(image_name), print(plt.imread(image_name).shape), print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('total number of trainig masks: ', 5332982)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'total number of trainig masks: ', np.sum(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278190, 278190)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "len(os.listdir('dataset/train/images')), len(os.listdir('dataset/train/labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def convert_mask_to_segmentation_(mask_path, output_txt_path, class_mapping):\n",
    "    # Load the mask image\n",
    "    mask_image = Image.open(mask_path)\n",
    "    \n",
    "    # Ensure the mask is in integer mode\n",
    "    if mask_image.mode not in ['L', 'I']:\n",
    "        mask_image = mask_image.convert('I')\n",
    "    \n",
    "    # Convert the mask image to a numpy array\n",
    "    mask_np = np.array(mask_image).astype(np.int32)\n",
    "    \n",
    "    # Identify unique labels (exclude 0 if it's background)\n",
    "    unique_labels = np.unique(mask_np)\n",
    "    unique_labels = unique_labels[unique_labels != 0]\n",
    "    \n",
    "    # Image dimensions for normalization\n",
    "    height, width = mask_np.shape[:2]\n",
    "    \n",
    "    # Open the output file\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        for label in unique_labels:\n",
    "            # Verify the label exists in class_mapping\n",
    "            if label not in class_mapping:\n",
    "                print(f\"Warning: Label {label} not found in class mapping.\")\n",
    "                continue\n",
    "            \n",
    "            # Create a binary mask for the current label\n",
    "            mask_bin = (mask_np == label).astype(np.uint8)\n",
    "            contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for contour in contours:\n",
    "                if len(contour) < 3:\n",
    "                    continue  # Skip if contour has less than 3 points\n",
    "\n",
    "                # Normalize and flatten the contour coordinates\n",
    "                contour = contour.reshape(-1, 2).astype(float)\n",
    "                contour[:, 0] = contour[:, 0] / width  # Normalize x\n",
    "                contour[:, 1] = contour[:, 1] / height  # Normalize y\n",
    "                segmentation = contour.flatten().round(6).tolist()\n",
    "                \n",
    "                # Format segmentation points as strings\n",
    "                segmentation_str = ' '.join(f\"{coord:.6f}\" for coord in segmentation)\n",
    "                class_id = class_mapping[label]\n",
    "                \n",
    "                # Write to file in format: <class_id> <points>\n",
    "                f.write(f\"{class_id} {segmentation_str}\\n\")\n",
    "\n",
    "\n",
    "class_mapping = {0: 1, 1: 2, 2: 3, 3: 4, 4:5, 5:6, 6:7, 7:8, 8:9, 9:10, 10:11, 11:12, 12:13, 13:14, 14:15, 15:16, 16:17, 17:18, 18:19, 19:20, 20:21, 21:22, 22:23, 23:24, \n",
    "                 24:25, 25:26, 26:27, 27:28, 28:29, 29:30, 30:31, 31:32, 32:33, 33:34, 34:35, 35:36, 36:37, 37:38, 38:39, 39:40, 40:41, 41:42, 42:43, 43:44, 44:45, 45:46, \n",
    "                 46:47, 47:48, 48:49, 49:50, 50:51, 51:52, 52:53, 53:54, 54:55, 55:56, 56:57, 57:58, 58:59, 59:60, 60:61, 61:62, 62:63, 63:64, 64:65, 65:66, 66:67, 67:68, \n",
    "                 68:69, 69:70, 70:71, 71:72, 72:73, 73:74, 74:75, 75:76, 76:77, 77:78, 78:79, 79:80, 80:81, 81:82, 82:83, 83:84, 84:85, 85:86, 86:87, 87:88, 88:89, 89:90, 90:91,\n",
    "                   91:92, 92:93, 93:94, 94:95, 95:96, 96:97, 97:98, 98:99, 99:100, 100:101, 101:102, 102:103, 103:104, 104:105, 105:106, 106:107, 107:108, 108:109, 109:110, 110:111, \n",
    "                   111:112, 112:113, 113:114, 114:115, 115:116, 116:117, 117:118, 118:119, 119:120, 120:121, 121:122, 122:123, 123:124, 124:125, 125:126, 126:127, 127:128, 128:129, \n",
    "                   129:130, 130:131, 131:132, 132:133, 133:134, 134:135, 135:136, 136:137, 137:138, 138:139, 139:140, 140:141, 141:142, 142:143, 143:144, 144:145, 145:146, 146:147, \n",
    "                   147:148, 148:149, 149:150, 150:151, 151:152, 152:153, 153:154, 154:155, 155:156, 156:157, 157:158, 158:159, 159:160, 160:161, 161:162, 162:163, 163:164, 164:165, \n",
    "                   165:166, 166:167, 167:168, 168:169, 169:170, 170:171, 171:172, 172:173, 173:174, 174:175, 175:176, 176:177, 177:178, 178:179, 179:180, 180:181, 181:182, 182:183,\n",
    "                     183:184, 184:185, 185:186, 186:187, 187:188, 188:189, 189:190, 190:191, 191:192, 192:193, 193:194, 194:195, 195:196, 196:197, 197:198, 198:199, 199:200, 200:201}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278190/278190 [15:57<00:00, 290.45it/s]\n"
     ]
    }
   ],
   "source": [
    "input_mask_path = 'dataset/train/masks/'\n",
    "file = os.listdir(input_mask_path)\n",
    "for i in tqdm.tqdm(range(len(file))):\n",
    "    input_mask_path = 'dataset/train/masks/' + file[i]\n",
    "    output_dir = 'dataset/train/labels/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_txt_path = output_dir + file[i].replace('.tiff', '.txt')\n",
    "    convert_mask_to_segmentation_(input_mask_path, output_txt_path, class_mapping)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25578/25578 [02:08<00:00, 198.63it/s]\n"
     ]
    }
   ],
   "source": [
    "input_mask_path = 'dataset/test/masks/'\n",
    "file = os.listdir(input_mask_path)\n",
    "for i in tqdm.tqdm(range(len(file))):\n",
    "    input_mask_path = 'dataset/test/masks/' + file[i]\n",
    "    output_dir = 'dataset/test/labels/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_txt_path = output_dir + file[i].replace('.tiff', '.txt')\n",
    "    convert_mask_to_segmentation_(input_mask_path, output_txt_path, class_mapping)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
