{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove the combined mask at first \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob \n",
    "combined_scan = glob.glob('New/s*/*/combined*')\n",
    "print(len(combined_scan ))\n",
    "# remove these files\n",
    "for file in combined_scan:\n",
    "    os.remove(file)\n",
    "combined_scan = glob.glob('New/s*/*/combined*')\n",
    "print(len(combined_scan ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_scan = glob.glob('New/s0001/segmentations/*')\n",
    "len(combined_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate labels found.\n",
      "Maximum label value: 117\n",
      "Number of unique labels: 117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('label_names.xlsx')\n",
    "\n",
    "# Extract the multiplied_labels column\n",
    "multiplied_labels = df['multiplied_labels'].tolist()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = [label for label in multiplied_labels if multiplied_labels.count(label) > 1]\n",
    "if duplicates:\n",
    "    print(\"Duplicate labels found:\", set(duplicates))\n",
    "else:\n",
    "    print(\"No duplicate labels found.\")\n",
    "\n",
    "# Check the maximum label value\n",
    "max_label = max(multiplied_labels)\n",
    "print(\"Maximum label value:\", max_label)\n",
    "\n",
    "# Check the number of unique labels\n",
    "unique_labels = set(multiplied_labels)\n",
    "print(\"Number of unique labels:\", len(unique_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adrenal_gland_left.nii.gz 117\n",
      "1 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders:   0%|          | 0/1228 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders: 100%|██████████| 1228/1228 [7:11:35<00:00, 21.09s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os \n",
    "\n",
    "# Load label information from Excel\n",
    "df = pd.read_excel('label_names.xlsx')\n",
    "label_names = df['label_names'].tolist()\n",
    "multiplied_labels = df['multiplied_labels'].tolist()\n",
    "print(label_names[0], len(label_names))\n",
    "print(multiplied_labels[0], len(multiplied_labels))\n",
    "\n",
    "# Get list of folders containing masks\n",
    "folders = glob.glob('New/s*/se*')\n",
    "folders.sort()\n",
    "\n",
    "for folder_num, folder in enumerate(tqdm.tqdm(folders, desc=\"Processing folders\")):\n",
    "    # Load one mask to get the shape and affine information\n",
    "    initial_file = os.path.join(folder, label_names[0])\n",
    "    initial_mask_nii = nib.load(initial_file)\n",
    "    mask_shape = initial_mask_nii.get_fdata().shape\n",
    "    affine = initial_mask_nii.affine\n",
    "\n",
    "    # Initialize the combined mask with zeros\n",
    "    combined_mask = np.zeros(mask_shape)\n",
    "    non_empty_label_count = 0\n",
    "    num_masks = []\n",
    "\n",
    "    for label_num, (label_name, label_value) in enumerate(zip(label_names, multiplied_labels)):\n",
    "        file_path = os.path.join(folder, label_name)\n",
    "        comb_file_path = os.path.join(folder, f'combined_mask.nii.gz')\n",
    "\n",
    "        file = nib.load(file_path)\n",
    "        mask = file.get_fdata()\n",
    "        combined_scan = nib.load(comb_file_path).get_fdata()\n",
    "\n",
    "        \n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        else:\n",
    "            non_empty_label_count += 1\n",
    "            num_masks.append(label_value)\n",
    "    \n",
    "    #print(num_masks)\n",
    "    #print(np.unique(combined_scan))\n",
    "    # get the unique values in between combined mask and num_masks\n",
    "    unique_values = np.unique(combined_scan)\n",
    "    unique_values = np.setdiff1d(unique_values, num_masks)\n",
    "    #print()\n",
    "    \n",
    "    if len(unique_values) > 1:\n",
    "        print(folder, len(np.unique(combined_scan)), unique_values)\n",
    "    #print(non_empty_label_count, len(np.unique(combined_scan)), unique_values)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('dataset_nii/val/labels/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1171/1171 [08:58<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "file = glob.glob('dataset_nii/*/labels/*')\n",
    "for f in tqdm(file):\n",
    "    mask = nib.load(f).get_fdata()\n",
    "    number = np.unique(mask)\n",
    "    if 117 in number:\n",
    "        print(f, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    1082\n",
       "test       89\n",
       "val        57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('meta.xlsx')\n",
    "df1 = df[df['split']=='train']\n",
    "print(len(df1))\n",
    "df2 = df[df['split']=='val']\n",
    "print(len(df2))\n",
    "len(df1) + len(df2)\n",
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'age', 'gender', 'institute', 'study_type', 'split',\n",
      "       'manufacturer', 'scanner_model', 'kvp', 'pathology',\n",
      "       'pathology_location'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [00:13<00:00, 82.04it/s] \n"
     ]
    }
   ],
   "source": [
    "# read the mketa.xlsx file \n",
    "import pandas as pd\n",
    "df = pd.read_excel('meta.xlsx')\n",
    "# select only train values in split column\n",
    "df = df[df['split']=='train']\n",
    "print(df.columns)\n",
    "# make directories for train and test\n",
    "import os\n",
    "os.makedirs('dataset_nii/train/images', exist_ok=True)\n",
    "os.makedirs('dataset_nii/train/labels', exist_ok=True)\n",
    "\n",
    "\n",
    "# get the name of images and labels\n",
    "files = df['image_id'].values\n",
    "# from these folders get the images and labels\n",
    "image_folder = 'New'\n",
    "label_folder = 'segmentations' \n",
    "import glob \n",
    "import tqdm\n",
    "for i in tqdm.tqdm(range(len(files))):\n",
    "\n",
    "    images = 'New/'+files[i]+'/ct.nii.gz'\n",
    "    labels = 'New/'+files[i]+'/segmentations/combined_mask.nii.gz'\n",
    "    # copy the images, change the name of the images sand then save them in the train folder\n",
    "    import shutil\n",
    "    shutil.copy(images, 'dataset_nii/train/images/'+files[i]+'.nii.gz') \n",
    "    shutil.copy(labels, 'dataset_nii/train/labels/'+files[i]+'.nii.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'age', 'gender', 'institute', 'study_type', 'split',\n",
      "       'manufacturer', 'scanner_model', 'kvp', 'pathology',\n",
      "       'pathology_location'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:01<00:00, 63.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# read the mketa.xlsx file \n",
    "import pandas as pd\n",
    "df = pd.read_excel('meta.xlsx')\n",
    "# select only train values in split column\n",
    "df = df[df['split']=='test']\n",
    "print(df.columns)\n",
    "# make directories for train and test\n",
    "import os\n",
    "\n",
    "os.makedirs('dataset_nii/test/images', exist_ok=True)\n",
    "os.makedirs('dataset_nii/test/labels', exist_ok=True)\n",
    "\n",
    "# get the name of images and labels\n",
    "files = df['image_id'].values\n",
    "# from these folders get the images and labels\n",
    "image_folder = 'New'\n",
    "label_folder = 'segmentations' \n",
    "import glob \n",
    "import tqdm\n",
    "for i in tqdm.tqdm(range(len(files))):\n",
    "\n",
    "    images = 'New/'+files[i]+'/ct.nii.gz'\n",
    "    labels = 'New/'+files[i]+'/segmentations/combined_mask.nii.gz'\n",
    "    # copy the images, change the name of the images sand then save them in the train folder\n",
    "    import shutil\n",
    "    shutil.copy(images, 'dataset_nii/test/images/'+files[i]+'.nii.gz') \n",
    "    shutil.copy(labels, 'dataset_nii/test/labels/'+files[i]+'.nii.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'age', 'gender', 'institute', 'study_type', 'split',\n",
      "       'manufacturer', 'scanner_model', 'kvp', 'pathology',\n",
      "       'pathology_location'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 79.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# read the mketa.xlsx file \n",
    "import pandas as pd\n",
    "df = pd.read_excel('meta.xlsx')\n",
    "# select only train values in split column\n",
    "df = df[df['split']=='val']\n",
    "print(df.columns)\n",
    "# make directories for train and test\n",
    "import os\n",
    "\n",
    "os.makedirs('dataset_nii/val/images', exist_ok=True)\n",
    "os.makedirs('dataset_nii/val/labels', exist_ok=True)\n",
    "\n",
    "# get the name of images and labels\n",
    "files = df['image_id'].values\n",
    "# from these folders get the images and labels\n",
    "image_folder = 'New'\n",
    "label_folder = 'segmentations' \n",
    "import glob \n",
    "import tqdm\n",
    "for i in tqdm.tqdm(range(len(files))):\n",
    "\n",
    "    images = 'New/'+files[i]+'/ct.nii.gz'\n",
    "    labels = 'New/'+files[i]+'/segmentations/combined_mask.nii.gz'\n",
    "    # copy the images, change the name of the images sand then save them in the train folder\n",
    "    import shutil\n",
    "    shutil.copy(images, 'dataset_nii/val/images/'+files[i]+'.nii.gz') \n",
    "    shutil.copy(labels, 'dataset_nii/val/labels/'+files[i]+'.nii.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "print(len('datase_nii/train/images/') == len('datase_nii/train/labels/'), len('datase_nii/test/images/') == len('datase_nii/test/labels/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [12:41<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocess CT scan \n",
    "import nibabel as nib\n",
    "import os \n",
    "import numpy as np\n",
    "import glob \n",
    "import tqdm\n",
    "def preprocess_ct_scan(ct_scan_path):\n",
    "    # Load the CT scan\n",
    "    ct_scan = nib.load(ct_scan_path)\n",
    "    affine = ct_scan.affine\n",
    "    # Get the pixel values\n",
    "    ct_scan_data = ct_scan.get_fdata()\n",
    "    \n",
    "    # Clip the pixel values to the range [0, 80]\n",
    "    ct_scan_data = np.clip(ct_scan_data, 0, 80)\n",
    "    \n",
    "    # save it as nifti file\n",
    "    ct_scan = nib.Nifti1Image(ct_scan_data, affine)\n",
    "    # save the file\n",
    "    nib.save(ct_scan, ct_scan_path)\n",
    "\n",
    "ct_files = glob.glob('dataset_nii/train/images/*')\n",
    "\n",
    "for ct_file in tqdm.tqdm(ct_files):\n",
    "    preprocess_ct_scan(ct_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'm_yolo' has no attribute 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ct_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_nii/val/images/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ct_file \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(ct_files):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mm_yolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241m.\u001b[39mpreprocess_ct_scan(ct_file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mm_yolo\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ct_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_nii/test/images/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'm_yolo' has no attribute 'preprocess'"
     ]
    }
   ],
   "source": [
    "import m_yolo\n",
    "ct_files = glob.glob('dataset_nii/val/images/*')\n",
    "\n",
    "for ct_file in tqdm.tqdm(ct_files):\n",
    "    m_yolo.preprocess.preprocess_ct_scan(ct_file)\n",
    "\n",
    "import m_yolo\n",
    "ct_files = glob.glob('dataset_nii/test/images/*')\n",
    "\n",
    "for ct_file in tqdm.tqdm(ct_files):\n",
    "    m_yolo.preprocess.preprocess_ct_scan(ct_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
